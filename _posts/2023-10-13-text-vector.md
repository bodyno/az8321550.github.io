---
layout: post
title: "关于文本向量化的学习"
date: 2023-10-13
tags: [vector learning]
categories: programing
---

### 关于文本向量化的学习

在现代的机器学习和人工智能应用中，文本数据的处理是一个重要的步骤。然而，对大多数机器学习算法来说，原始的文本数据并不适合直接使用，因为它们不是数值型数据，也没有明确的格式。这就是我们需要文本向量化的原因。

文本向量化是一种将文本数据转化为数值型数据的技术。这种转化过程通常包括以下几个步骤：

分词：这是将文本分解为单词或短语的过程。例如，"我爱你"被分词为"我"、"爱"、"你"。

停用词移除：停用词是指在文本中频繁出现但对文本意义贡献不大的词，如"的"、"是"、"在"等。移除这些词可以减少数据的复杂性，提高模型的效率。

词干提取/词形还原：这是将单词转换为其基本形式的过程。例如，"running"经过词干提取后变为"run"。

编码：将每个单词或短语转换为一个数值型向量。这个过程通常使用一种称为词嵌入的技术来实现。词嵌入是将高维空间中的向量映射到低维空间，使得语义上相似的词在向量空间中也是接近的。

池化（可选）：如果数据集非常大，可能需要进行池化操作，将大的文档集合划分为小的文档集合，然后将每个文档集合向量化。

通过以上步骤，我们就可以得到一组数值型的向量，这些向量可以作为机器学习模型的输入。例如，可以使用这组向量来训练文本分类器、情感分析器、命名实体识别器等模型。

### 文本向量化 和 ChatGPT

不同于传统数据库的模糊搜索/匹配关键字，我们需要进行语义/特征匹配。

例如：你搜索『猫』，只能得到带 『猫』 关键字匹配的结果，没办法得到 『布偶』、『蓝白』 等结果，传统数据库认为『布偶』是『布偶』、『猫』是『猫』。要实现关联语义搜索，是通过人工打特征标签，这个过程也被称为特征工程（Feature Engineering）。

如何才能将文本自动化的方式来提取这些特征？这就要通过 Vector Embedding 向量化实现，目前社区通过 OpenAI 提供的 text-embedding-ada-002 模型生成，这会引起两个问题：

### 应用

ChatGPT 单次调用都有 token 上限的限制，只能支持4000个token（约3000个词）的输入，所以我们需要先使用文本向量化，在向量数据库中找到最匹配的内容，组合成 Prompt 向 ChatGPT 提问，同时建立起自己的内嵌知识库，这样，才能使答案更精确。

ChatGPT 并不懂逻辑，它的一切只是基于概率的计算，如果有人告诉你它可以通过逻辑推理出某些定理，那这个人一定在忽悠你。

最近在结合 LLM 大语言模型做一个自动 Code Review 的项目尝试，希望能取得不错的效果，不断挖掘 ChatGPT 的潜力，改变就在眼前。













